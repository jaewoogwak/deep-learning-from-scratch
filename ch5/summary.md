# 오차역전파법

## Computational graph

-   계산 그래프는 노드와 에지로 표현된다.
    ![graph](IMG_2AFC99D625DE-1.jpeg)

-   계산 그래프를 이용한 문제풀이는 다음 흐름과 같다.

1. 계산 그래프 구성
2. 그래프에서 계산을 왼쪽에서 오른쪽으로 진행

-   이때 계산을 왼쪽에서 오른쪽으로 진행하는 단계를 순전파(forward propagation)라고 한다.
-   반대로 오른쪽에서 왼쪽으로 전파는 역전파(backward propagation)라고 한다.
-   계산 그래프는 국소적 계산에 집중한다.
-   각 노드는 자신의 계산만 하면 된다.
-   그렇게 함으로써 전체를 구성하는 복잡한 계산을 해낼 수 있다. 이게 핵심
-   딥러닝에 적용하면 역전파를 통해 미분을 효율적으로 계산할 수 있음

## 역전파 계산 핵심

-   변화율은 곧 미분이다.
-   `dz`의 변화는 `dz`의 미분이다.
-   변화는 다른 값에 의해 발생한다. (`dz`는 종속적임.)
-   `z = f(x+y)`의 경우 `x`와 `y`에 대해 `z`가 변화한다.
-   즉, `x`와 `y`에 대한 `z`의 미분이다.
-   순전파 방향에서 '~에 대한'에 위치한 변수가 아래에 오고 노드 뒤에 출력으로 나오는 변수가 위에 온다.

## [240229] 딥러닝에서 학습은 어떻게 하는걸까?

딥러닝에서는 가장 흔히 사용하는 MNIST 데이터셋을 가장 흔히 사용한다.

6만 장의 0부터 9까지의 손글씨 훈련 데이터를 신경망에 넣고 학습시킨다.

딥러닝에서는 신경망이 존재한다.

신경망의 연산은 xw + b = y로 간단하다. 이렇게 해서 나온 출력 y를 activation 함수에 넣고 최종 출력을 얻는다. (predict)

이 과정이 신경망 한 층에 대한 것이다.

딥러닝은 이런 신경망을 여러 층 쌓아서 활용한다. 이렇게 여러 층 통과하여 나온 최종 출력을 어디에 활용할까?

이 출력과 정답과 얼마나 비슷한지 비교하는 과정을 거친다. (오차 구하기)

이제 오차를 줄인다면 우리가 설계한 신경망이 정답을 더 잘 내게 된다.

오차를 줄이는 게 딥러닝 문제의 핵심이다.

오차는 경사법으로 줄일 수 있다.
